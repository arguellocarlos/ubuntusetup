services:
  api:
    image: localai/localai:latest-aio-gpu-intel
    container_name: localai-intel
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 1m
      timeout: 20m
      retries: 5
    ports:
      - 8082:8080
    devices:
      - /dev/dri:/dev/dri
    environment:
      - DEBUG=true
      - LOCALAI_SINGLE_ACTIVE_BACKEND=true
      # ...
    volumes:
      - ./models:/models:cached
    # decomment the following piece if running with Nvidia GPUs
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
